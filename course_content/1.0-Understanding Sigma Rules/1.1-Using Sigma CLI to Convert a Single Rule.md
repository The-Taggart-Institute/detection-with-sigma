# 1.1 :: Using Sigma CLI to Convert a Single Rule

Now that we have seen a couple of rules and have a basic understanding of the structure of Sigma, we can start to convert rules on our own. To do this we will use SigmaCLI to convert a single rule and search for events in our SIEM.

We will use `pip` to install the Sigma-CLI tool which is built on top of the PySigma library. For the remainder of this course we will heavily use Sigma-CLI to automatically convert our rules and thus understanding the PySigma library is not necessary. If you are curious, it is well documented here: [https://sigmahq-pysigma.readthedocs.io/en/latest/](https://sigmahq-pysigma.readthedocs.io/en/latest/).

Once we have Sigma-CLI installed, we will make a folder where we will store our rules and use the tool to convert the rules into SPL and savedsearches.conf format. 

Follow these steps:
- Install Sigma-CLI
	- `python -m pipx install sigma-cli`
	- `echo 'export PATH=$PATH:~/.local/bin' >> ~/.bashrc`
	- `sigma plugin install splunk`
- Setup the testing environment:
	- `mkdir ~/sigma_test && cd ~/sigma_test`
	- `mkdir rules`
	- `code rules/dns_query_win_mal_cobaltstrike.yml`
- Copy and paste the following rule into Visual Studio Code:

```yaml
title: Suspicious Cobalt Strike DNS Beaconing - Sysmon
id: f356a9c4-effd-4608-bbf8-408afd5cd006
related:
    - id: 0d18728b-f5bf-4381-9dcf-915539fff6c2
      type: similar
status: test
description: Detects a program that invoked suspicious DNS queries known from Cobalt Strike beacons
references:
    - https://www.icebrg.io/blog/footprints-of-fin7-tracking-actor-patterns
    - https://www.sekoia.io/en/hunting-and-detecting-cobalt-strike/
author: Florian Roth (Nextron Systems)
date: 2021/11/09
modified: 2023/01/16
tags:
    - attack.command_and_control
    - attack.t1071.004
logsource:
    product: windows
    category: dns_query
detection:
    selection1:
        QueryName|startswith:
            - 'aaa.stage.'
            - 'post.1'
    selection2:
        QueryName|contains: '.stage.123456.'
    condition: 1 of selection*
falsepositives:
    - Unknown
fields:
    - Image
    - CommandLine
level: critical
```

Convert the rule by running the following command back in your terminal:
	- `sigma convert --target splunk --pipeline splunk_windows /rules`

The output here is the rule converted into SPL! Now let's try changing the output format to the `savedsearches.conf` format that Splunk will use to create automatically scheduled searches.

Run the following command:

```shell
sigma convert --format savedsearches --target splunk --pipeline splunk_windows ~/sigma_test/rules
```

This outputs a rule in `savedsearches.conf` format. Now we can overwrite the `.conf` file in `~/sigma-course/apps/sigma/local/savedsearches.conf`

By doing this, we are modifying the configuration file that Splunk uses to schedule searches. But first, we need to tell Splunk to refresh and reload the configurations before they will run. In your web browser, navigate to `http://<splunk_host>:8000/debug/refresh` and hit the refresh button. Return back to the Splunk homepage and select the Apps button, then your Sigma app, then the Reports tab. Take a moment now to marvel at your new search! 

You have successfully converted a single Sigma rule using Sigma-CLI and have seen the output of this rule in both standard SPL and in the savedsearches.conf format that is used by Splunk to schedule searches in the background. This conversion used a basic processing pipeline that did not do any field name transformations or define an index to search in. Because of this, this search will not actually find any results in your production environment. Additionally, the search does not have any instructions on how often it should run as we did not define any schedule.

In the next section we will discuss how to build our own processing pipeline and pass it to Sigma CLI so that we can convert generic Sigma standard field names into our own custom-defined field names,    assign a mapping between log sources and indexes, and instruct Splunk to schedule the search on a periodic basis.

### Check for Understanding

**Follow these steps again and convert another rule of your choice from the [public Sigma repo](https://github.com/SigmaHQ/sigma) automatically and append it to your savedsearches.conf file.**
